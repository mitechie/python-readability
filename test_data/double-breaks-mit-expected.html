<body><html>
  <div class="articlebody"><p>
    Recommendation algorithms are a vital part of today&acirc;&euro;&trade;s
    Web, the basis of the targeted advertisements that account for most
    commercial sites&acirc;&euro;&trade; revenues and of services such as
    Pandora, the Internet radio site that tailors song selections to
    listeners&acirc;&euro;&trade; declared preferences. The DVD rental site
    Netflix deemed its recommendation algorithms important enough that it
    offered a million-dollar prize to anyone who could improve their
    predictions by 10 percent.
    </p><p>
    But Devavrat Shah, the Jamieson Career Development Associate Professor of
    Electrical Engineering and Computer Science in MIT&acirc;&euro;&trade;s
    Laboratory of Information and Decisions Systems, thinks that the most
    common approach to recommendation systems is fundamentally flawed. Shah
    believes that, instead of asking users to rate products on, say, a
    five-star scale, as Netflix and Amazon do, recommendation systems should
    ask users to compare products in pairs. Stitching the pairwise rankings
    into a master list, Shah argues, will offer a more accurate representation
    of consumers&acirc;&euro;&trade; preferences.
    </p><p>
    In a series of papers (<a href="http://web.mit.edu/devavrat/www/nips2008.pdf" target=
    "_blank">paper 1</a> | <a href="http://arxiv.org/abs/0910.0895" target="_blank">paper
    2</a> | <a href="http://arxiv.org/abs/0910.0063" target="_blank">paper 3</a>)
    published over the last few years, Shah, his students Ammar Ammar and
    Srikanth Jagabathula, and Vivek Farias, an associate professor at the MIT
    Sloan School of Management, have demonstrated algorithms that put that
    theory into practice. Besides showing how the algorithms can tailor product
    recommendations to customers, they&acirc;&euro;&trade;ve also built a <a href="http://celect.lids.mit.edu/" target= "_blank">website</a> that
    uses the algorithms to help large groups make collective decisions. And at
    an Institute for Operations Research and Management Sciences conference in
    June, they presented a version of their algorithm that had been tested on
    detailed data about car sales collected over the span of a year by auto
    dealers around the country. Their algorithm predicted car
    buyers&acirc;&euro;&trade; preferences with 20 percent greater accuracy
    than existing algorithms.
    </p><p><strong>Calibration conundrum</strong>
    </p><p>
    One of the problems with basing recommendations on ratings, Shah explains,
    is that an individual&acirc;&euro;&trade;s rating scale will tend to
    fluctuate.  &acirc;&euro;&oelig;If my mood is bad today, I might give four
    stars, but tomorrow I&acirc;&euro;&trade;d give five stars,&acirc;&euro; he
    says. &acirc;&euro;&oelig;But if you ask me to compare two movies, most
    likely I will remain true to that for a while.&acirc;&euro;
    </p><p>
    Similarly, ratings scales may vary between people. &acirc;&euro;&oelig;Your
    three stars might be my five stars, or vice versa,&acirc;&euro; Shah says.
    &acirc;&euro;&oelig;For that reason, I strongly believe that comparison is
    the right way to capture this.&acirc;&euro;
    </p><p>
    Moreover, Shah explains, anyone who walks into a store and selects one
    product from among the three displayed on a shelf is making an implicit
    comparison. So in many contexts, comparison data is actually easier to come
    by than ratings.
    </p><p>
    Shah believes that the advantages of using comparison as the basis for
    recommendation systems are obvious but that the computational complexity of
    the approach has prevented its wide adoption. The results of thousands
    &acirc;&euro;&rdquo; or millions &acirc;&euro;&rdquo; of pairwise
    comparisons could, of course, be contradictory: Some people may like
    "Citizen Kane" better than "The Godfather," but others may like "The
    Godfather" better than "Citizen Kane." The only sensible way to interpret
    conflicting comparisons is statistically. But there are more than three
    million ways to order a ranking of only 10 movies, and every one of them
    may have some probability, no matter how slight, of representing the ideal
    ordering of at least one ranker. Increase the number of movies to 20, and
    there are more ways to order the list than there are atoms in the
    universe.
    </p><p><strong>Ordering out</strong>
    </p><p>
    So Shah and his colleagues make some assumptions that drastically reduce
    the number of possible orderings they have to consider. The first is simply
    to throw out the outliers. For example, Netflix&acirc;&euro;&trade;s
    movie-rental data assigns the Robin Williams vehicle "Patch Adams" the
    worst reviews, on average, of any film with a statistically significant
    number of ratings. So the MIT algorithm would simply disregard all the
    possible orderings in which "Patch Adams" ranked highly.
    </p><p>
    Even with the outliers eliminated, however, a large number of plausible
    orderings might remain. From that group, the MIT algorithm selects a
    subset: the smallest group of orderings that fit the available data. This
    approach can winnow an astronomically large number of orderings down to one
    that&acirc;&euro;&trade;s within the computational purview of a modern
    computer.
    </p><p>
    Finally, when the algorithm has arrived at a reduced number of orderings,
    it uses a movie&acirc;&euro;&trade;s rank in each of the orderings,
    combined with the probability of that ordering, to assign the movie an
    overall score. Those scores determine the final ordering.
    </p><p>
    Paat Rusmevichientong, an associate professor of information and operations
    management at the University of Southern California, thinks that the most
    interesting aspect of Shah&acirc;&euro;&trade;s work is the alternative it
    provides to so-called parametric models, which are more restrictive. These,
    he says, were &acirc;&euro;&oelig;the state of the art up until 2008, when
    Professor Shah&acirc;&euro;&trade;s paper first came out.&acirc;&euro;
    </p><p>
    &acirc;&euro;&oelig;They&acirc;&euro;&trade;ve really, substantially
    enlarged the class of choice models that you can work with,&acirc;&euro;
    Rusmevichientong says.  &acirc;&euro;&oelig;Before, people never thought
    that it was possible to have rich, complex choice models like
    this.&acirc;&euro;
    </p><p>
    The next step, Rusmevichientong says, is to test that type of model
    selection against real-world data. The analysis of car sales is an early
    example of that kind of testing, and the MIT researchers are currently
    working up a version of their conference paper for journal publication.
    &acirc;&euro;&oelig;I&acirc;&euro;&trade;ve been waiting to see the
    paper,&acirc;&euro; Rusmevichientong says.  &acirc;&euro;&oelig;That sounds
    really exciting.&acirc;&euro;
    </p></div>
</body></html>
